---
title: "Predicting income non-response in survey"
author: "Tong Wu"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, message=FALSE, include=FALSE}
library(pander)
library(dplyr)
library(tidyverse)
library(car)
library(ResourceSelection)
library(MASS)
library(bestglm)
library(caret)
library(doParallel)
library(foreach)
setwd("F:/Tong/Data Study/VUW/DATA303/Assignment 4")
```

# Variable recodes and missing data analysis

- In order to better analysis, create a new binary variable INCOME_NONRESPONSE to show whether the person provide a numerical income data or not. 0 = “Provided numeric income data”, 1 = “Did not provide numeric income data”. And check the frequency of the outcomes to have an understanding whether our data is balanced.
- Re-struct the data by focusing on a subset of demographic variables and those generally associated with income. Remove the missing value and make sure the portion is not large to affect the whole process later.


```{r}
# Load data set
wtp <- read.csv("WTP.csv")

# Produce new variable to show if provide a numerical total income
wtp$INCOME_NONRESPONSE <- ifelse(is.na(wtp$TOTAL_INCOME),1,0)
head(wtp)

# Table of frequency of outcomes of 0 and 1
table(wtp$INCOME_NONRESPONSE)
```

```{r}
# Create subset of 9 variables only
wtp.reduced <- wtp[, c("TOWN", "SEX", "AGE", "EDUC", "HEAD", "PAY_WATER", "ELECTRIC", "TIME_LENGTH", "INCOME_NONRESPONSE")]

# Define special codes that refer to missing value and convert those to NA
missing.codes <- c(-1, 9998, 9999)
wtp.cleaned <- wtp.reduced %>%
  mutate(across(everything(), ~ replace(., . %in% missing.codes, NA)))

# Create new data frame that remove missing data NA
wtp.complete <- na.omit(wtp.cleaned)
head(wtp.complete)

# Calculate the proportion of observations removed from original data set
removed.rows <- nrow(wtp) - nrow(wtp.complete)
proportion.removed <- round(removed.rows / nrow(wtp),3)
proportion.removed
```

```{r}
# Check variables current status and convert those needs to be factor
str(wtp.complete)

factor.vars <- c("TOWN", "SEX", "EDUC", "HEAD", "PAY_WATER", "ELECTRIC")
wtp.complete[factor.vars] <- lapply(wtp.complete[factor.vars], as.factor)
str(wtp.complete)
```

# Inferential analysis

- Evaluate how non-response to a question asking for a numeric value for the total average
monthly income of the household is related to demographic factors of the respondent and proxies for
income.
- Fit different models and carry out likelihood ratio test to check which model is better fit.

```{r}
# Fit logistic regression model
model <- glm(INCOME_NONRESPONSE ~ TOWN + SEX + AGE + EDUC + HEAD + PAY_WATER + ELECTRIC + TIME_LENGTH, data = wtp.complete, family = "binomial")

# Calculate VIF to check the multicollinearity
model.vif <- vif(model)
vif.value <- round(model.vif, 3)
vif.value

# Get model summary to see what variable is significant 
summary(model)
```

```{r}
# Fit a model with interactions and produce summary
model.interactions <- glm(INCOME_NONRESPONSE ~ TOWN + SEX + AGE + EDUC + HEAD + PAY_WATER + ELECTRIC + TIME_LENGTH + SEX:PAY_WATER + SEX:ELECTRIC, data = wtp.complete, family = "binomial")
summary(model.interactions)
```

```{r}
# Carry out likelihood ratio test
model <- glm(INCOME_NONRESPONSE ~ SEX + AGE + EDUC + PAY_WATER + ELECTRIC, data = wtp.complete, family = "binomial")

model.interactions <- glm(INCOME_NONRESPONSE ~ SEX + AGE + EDUC + PAY_WATER + ELECTRIC + SEX:PAY_WATER + SEX:ELECTRIC, data = wtp.complete, family = "binomial")

pander(anova(model, model.interactions, test = "Chisq"))
```

```{r}
# performance Hosmer-Lemeshow test
hl.5 <- hoslem.test(wtp.complete$INCOME_NONRESPONSE,fitted(model.interactions), g=5)
hl.10 <- hoslem.test(wtp.complete$INCOME_NONRESPONSE,fitted(model.interactions), g=10)
hl.15 <- hoslem.test(wtp.complete$INCOME_NONRESPONSE,fitted(model.interactions), g=15)

# create summary table
hl.results <- data.frame(
  Groups = c(5,10,15),
  Chi_Squared = c(hl.5$statistic, hl.10$statistic, hl.15$statistic),
  DF = c(hl.5$parameter, hl.10$parameter, hl.15$parameter),
  P_value = c(hl.5$p.value, hl.10$p.value, hl.15$p.value)
)

hl.results
```

# Statistical learning

- Will perform an exploratory analysis to try to identify the best set of predictors in predicting
whether a respondent will not report a numeric value for income.
- Use forward, backward and best subset selection, and also try cross-validation based on AUC.


```{r}
# perform forward selection 
forward.selection <- stepAIC(glm(INCOME_NONRESPONSE ~ 1, data = wtp.complete, family = "binomial"), scope = list(upper = ~ TOWN + SEX + AGE + EDUC + HEAD + PAY_WATER + ELECTRIC + TIME_LENGTH, lower = ~1), direction = "forward", trace = FALSE)

# perform backward selection
backward.selection <- stepAIC(glm(INCOME_NONRESPONSE ~ TOWN + SEX + AGE + EDUC + HEAD + PAY_WATER + ELECTRIC + TIME_LENGTH, data = wtp.complete, family = "binomial"), scope = list(upper = ~ TOWN + SEX + AGE + EDUC + HEAD + PAY_WATER + ELECTRIC + TIME_LENGTH, lower = ~1), direction = "backward", trace = FALSE)

forward.selection$anova
backward.selection$anova
```

```{r}
# prepare dataset in format required by bestglm
predictors.for.bestglm <- data.frame(
  TOWN = as.factor(wtp.complete$TOWN), 
  SEX = as.factor(wtp.complete$SEX), 
  AGE = wtp.complete$AGE, 
  EDUC = as.factor(wtp.complete$EDUC), 
  HEAD = as.factor(wtp.complete$HEAD), 
  PAY_WATER = as.factor(wtp.complete$PAY_WATER), 
  ELECTRIC = as.factor(wtp.complete$ELECTRIC), 
  TIME_LENGTH = wtp.complete$TIME_LENGTH, 
  y = wtp.complete$INCOME_NONRESPONSE)

# find best logistic regression model in terms of AIC
best.logistic.AIC <- bestglm(Xy = predictors.for.bestglm, family = binomial, 
                             IC = "AIC", method = "exhaustive")

# find best logistic regression model in terms of BIC
best.logistic.BIC <- bestglm(Xy = predictors.for.bestglm,family = binomial, 
                             IC = "BIC", method = "exhaustive") 

best.logistic.AIC$BestModels
best.logistic.BIC$BestModels
```


```{r}
# specify the indices of the variables to be considered 
set.seed(0)
names(wtp.complete)
variable.indices <- 1:8

# produce matrix that represents all possible combinations of variables
all.comb <- expand.grid(as.data.frame(matrix(rep(0 : 1, length(variable.indices)), nrow = 2)))[-1,]


# specify the number of folds and repetitions
folds <- 10
reps <- 20

# fire up 75% of cores for parallel processing.
nclust <- makeCluster(detectCores() * 0.75)
registerDoParallel(nclust)

# specify settings for repeated 10-folds cross validation for accuracy
fitControl <- trainControl(
  method = "repeatedcv", 
  number = folds, 
  repeats = reps, 
  seeds = 1 : (folds * reps + 1), 
  classProbs = TRUE, 
  savePredictions = TRUE
)

# produce accuracy
accuracy <- foreach(i = 1 : nrow(all.comb), .combine = "rbind", .packages = "caret") %dopar%
{
c(i, unlist(train(as.formula(paste("make.names(INCOME_NONRESPONSE) ~",
paste(names(wtp.complete)[variable.indices][all.comb[i,] == 1], collapse = " + "))), data
= wtp.complete, trControl = fitControl, method = "glm", family = "binomial", metric =
"Accuracy")$results[c(2, 4)]))
}

rownames(accuracy) <- NULL
```

```{r}
# produce AUC
fitControl <- trainControl(
  method = "repeatedcv", 
  number = folds, 
  repeats = reps, 
  seeds = 1 : (folds * reps + 1), 
  summaryFunction = twoClassSummary, 
  classProbs = TRUE, 
  savePredictions = TRUE
)

# Save estimated AUC and standard errors for each set of covariates.
AUC <- foreach(i = 1 : nrow(all.comb), .combine = "rbind", .packages = "caret") %dopar%
{
c(i, unlist(train(as.formula(paste("make.names(INCOME_NONRESPONSE) ~",
paste(names(wtp.complete)[variable.indices][all.comb[i,] == 1], collapse = " + "))), data
= wtp.complete, trControl = fitControl, method = "glm", family = "binomial", metric =
"ROC")$results[c(2, 5)]))
}

rownames(AUC) <- NULL
```

```{r}
# shut down cores
stopCluster(nclust)
```

```{r}
# show the optimal models by accuracy
best.acc <- accuracy[which.max(accuracy[, 2]), ]
best.model.acc <- all.comb[best.acc[1], ]  
best.model.acc

predictor.names <- c("TOWN", "SEX", "AGE", "EDUC", "HEAD", "PAY_WATER", "ELECTRIC", "TIME_LENGTH")
selected.predictors.acc <- predictor.names[which(as.logical(best.model.acc))]
selected.predictors.acc

# show the optimal models by AUC
best.auc <- AUC[which.max(AUC[,2]),]
best.model.auc <- all.comb[best.auc[1],]
best.model.auc

selected.predictors.auc <- predictor.names[which(as.logical(best.model.auc))]
selected.predictors.auc
```




